#+TITLE: MA341 - Real Analysis - Spring 2016
* Infimum and Supremum of sequences
#+begin_theorem
Let $(x_n)$ be a monotonic sequence.  

If $(x_n)$ is bounded then it is convergent

and $$\lim_{n\to\infty} x_n = \sup(x_n, n \in \mathbb{N})$$ or $\inf(x_n, n \in \mathbb{N})$
#+end_theorem
#+begin_proof
Let $(x_n)$ be increasing and bounded and $x = \sup(x_n, n \in \mathbb{N})$

Let $\varepsilon > 0$,

then $x - \varepsilon$ is not upper bound.

You can find $N$ s.t. $x - \varepsilon < x_n \leq x$

Since $(x_n)$ increasing, 
$x \geq x_N$

Let $(-x_n)$ be increasing and bounded

So $$\lim_{n\to\infty} (-x_n) = \sup(-x_n) = -\inf(x_n)$$

So $$\lim_{n\to\infty} = \inf(x_n)$$
#+end_proof
#+begin_examples
1. $x_n = \frac{1}{n}$

   $x_n$ is decreasing and bounded, so it converges to $\inf(\frac{1}{n}) = 0$

2. $x_n = 1 + \frac{1}{2} + ... + \frac{1}{n}$

   $(x_n)$ is increasing. We will show it is not bounded.

   $x_n = 1 + \frac{1}{2} + (\frac{1}{3} + \frac{1}{4}) + ... \\

   \geq 1 + \frac{1}{2} + (\frac{1}{4} + \frac{1}{4}) + ... = 1 + \frac{n}{2}$

   So $x_n$ is not bounded

3. Let $x_n$ be defined

   $x_1 = 1$

   $x_{n+1} = \frac{1}{4}(2x + 3)$

   First prove that $x_n$ is increasing. (by induction)

   $x_1 < x_2$

   $\frac{1}{4}(2x_n + 3) \leq \frac{1}{4}(2x_{n+1} + 3)$

   so $x_n \leq x_{n+1}$

   *Show bounded* (by induction)

   $x_1 \leq 2$

   Assume $x_n \leq 2$, then

   $x_{n+1} = \frac{1}{4}(2x_n + 3) \leq \frac{7}{4} \leq 2$

   so $x_n$ is bounded.

   Now to find the limit. $x_n = x_{n+1}$

   so $x = \frac{1}{4}(2x + 3) \Rightarrow x = \frac{3}{2}$
#+end_examples

* Subsequences
#+begin_definition
_subsequence_ 

Let $(y_n)$ be a sequence.

If the sequence $(x_n) \subseteq (y_n)$

Then $(x_n)$ is a subsequence of $(y_n)$
#+end_definition
#+begin_examples
 $(2,4,6,8,...)$ is a subsequence of $(1,2,3,4,...)$
 
 $x_n = (-1)^n$     $(-1,1,-1,1,...)$

 $x_n = 1$        $(1,1,1,1,...)$

 $x_n = -1$       $(-1,-1,-1,-1,...)$  
#+end_examples
** Convergence
#+begin_theorem
Let $(x_n)$ be a convergent sequence

Then all subsequences are also convergent and the limits are the same.
#+end_theorem
#+begin_proof
Let $$x = \lim_{x \to \infty} x_n$$

Let $\varepsilon > 0$.  We can find $f(\varepsilon)$ s.t. $|x_n - x| \leq \varepsilon$ for $n \geq f(\varepsilon)$

Since $n_k$ is strictly increasing, $n_k \geq k$

For $k \geq f(\varepsilon), n_k \geq k \geq f(\varepsilon)$

so $|x_{n_k} - x| \leq \varepsilon$ and $$\lim_{k\to\infty} x_{n_k} = x$$
#+end_proof
#+begin_examples
1.  $x_n = \frac{1}{n^4}$

    Since $n^4 \in \mathbb{N}$, $x_n$ is a subsequence of $\frac{1}{n}$.

    So $x_n$ must also converge to 0.

2.  $x_n = (-1)^n$

    $$\lim_{n\to\infty} x_{2n} = 1$$

    $$\lim_{n\to\infty} x_{2n+1}= -1$$

    So $x_n$ is divergent
#+end_examples

** Divergence
#+begin_theorem
Similarly, if $(x_n)$ is a sequence and $(y_n)$ is a divergent subsequence

then $(x_n)$ is divergent
#+end_theorem
#+begin_proof
Let $(x_n)$ be a sequence.

Then $(x_n)$ does not converge if we can find $\varepsilon_0 > 0$ s.t. $\forall K \geq 0, \exists n_K \geq K, |x_{n_K} - x| > \varepsilon_0$

So if $(x_n)$ does not converge to $x$, we can find $\varepsilon_0 > 0$ and a subsequence $(x_m)$ s.t. $\forall k \in \mathbb{N}, | x_m - x | > \varepsilon_0$
#+end_proof
** Monotonicity
#+begin_theorem
Let $(x_n)$ be a sequence.

There exists a subsequence $(x_m)$ which is monotonic
#+end_theorem
#+begin_proof
Define $x_m$ to be a peak if $x_n \leq x_m$ for $n \geq m$

Two cases:

1. $(x_n)$ has infinitely many peaks

   Let  \[x_{n_1},x_{n_2},x_{n_3},...\] be a sequence of peaks.

   Then \[x_{n_1} \geq x_{n_2} \geq x_{n_3} \geq ...\]

   So the subsequence is increasing

2. $(x_n)$ has finite number of peaks

   Then you can find $N$ s.t. $\forall n \geq N$, $x_n$ is not a peak

   Then the subsequence \[x_{n_N},x_{n_{N+1}},x_{n_{N+2}},...\] must be increasing (they are not peaks)
#+end_proof

* Bolzano-Weierstrauss
#+begin_theorem
Let $(x_n)$ be a bounded sequence

Then there exists a subsequence $(x_m)$ that is convergent
#+end_theorem
#+begin_proof
[[./bolzana.png]]
Let $a,b \in \mathbb{R}$ s.t. $\forall n \in \mathbb{N}, x_n \in [a,b]$

Then either $[a,\frac{a+b}{2}]$ or $[\frac{a+b}{2},b]$ is contains an infinite subsequence of $(x_n)$. 
Call this $I_1$.

By induction, construct $I_n$
  - width of $I_n = \frac{b-a}{2}$
  - $I_{n+1} \in I_n$
  - $\{k \in \mathbb{N} | x_k \in I_n \}$ is infinite

We know $\cap I_n$ is nonempty

Let $x \in \cap I_n$

We can construct subsequence $x_{n_k}$ such that $x_{n_k} \in I_k$

Since $x \in I_k$ and $| x_{n_k} - x| \leq \frac{b-a}{2}$

$$\lim_{k \to \infty} x_{n_k} = x$$
#+end_proof
#+begin_examples
1. $x_n = (-1)^n$

   $x_{2n} \Rightarrow 1$

   $x_{2n+1} \Rightarrow -1$

2. Any subsequence of $(x_n) = \sin(n)$ can converge to any $x \in [-1,1]$
#+end_examples

* Cauchy Sequence
#+begin_definition
*cauchy sequence*

Let $(x_n)$ be a sequence.

$(x_n)$ is a cauchy sequence if $\forall \varepsilon > 0$ $\exists K(\varepsilon) \geq 0$

$\forall n,m \geq K(\varepsilon), | x_n - x_m | \leq \varepsilon$
#+end_definition

** Cauchy and inverses
#+begin_theorem
Let $(x_n)$ be a convergent sequence.

Then it is a Cauchy sequence

The inverse is not true
#+end_theorem
#+begin_proof
Let $\varepsilon > 0$.  

Let $$x = \lim_{n \to \infty} x_n$$

$\exists K(\varepsilon) \geq 0$ such that $\forall n \geq K(\varepsilon)$ $|x_n - x| \leq \frac{\varepsilon}{2}$

For $n,m \geq K(\varepsilon)$,

$$ \begin{aligned}
\ |x_n - x_m| & = |x_n - x + x - x_m| \\
& \leq |x_n + x| + |x - x_m| \\
& \leq \frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon \\
\end{aligned} $$

So $(x_n)$ is a Cauchy sequence
#+end_proof
#+begin_examples
1. Not a Cauchy sequence:

   $(x_n) = \sqrt{n}$ 

   $(x_n)$ is Cauchy, but does not converge
#+end_examples

#+begin_theorem - Convergence of Cauchy sequences
Let $(x_n)$ be a Cauchy sequence

Then $(x_n)$ is convergent
#+end_theorem
#+begin_proof
Let $(x_n)$ be a Cauchy sequence.  Then $(x_n)$ is bounded and has a convergent subsequence $(x_{n_k})$

s.t. $$\lim (x_{n_k}) = x$$

Let $\varepsilon \geq 0$. 

There exists $K(\varepsilon) \geq 0$ s.t. $\forall n,m \geq K(\varepsilon), |x_n - x_m| \leq \varepsilon$

there exists $N \geq K(\varepsilon), |x - x_n| \leq \varepsilon$

For $n \geq K(\varepsilon)$

$$ \begin{aligned}
\ |x_n - x| & = |x_n - x_N + x_N - x| \\
& \leq |x_n - x_N| + |x_N - x| \\
& \leq \varepsilon + \varepsilon = 2 \varepsilon
\end{aligned} $$
#+end_proof
#+begin_examples
1. $x_n = 1 + \frac{1}{2} + ... + \frac{1}{n}$

   $x_{2n} - x_n = \frac{1}{n+1} + \frac{1}{n+2} + ... + \frac{1}{2n} \geq \frac{1}{2n} + ... + \geq \frac{1}{2n}$

   So $x_{2n} - x_n$ does not converge to $0$ therefore $(x_n)$ is not a Cauchy sequence
#+end_examples
* Contracting Sequences
#+begin_definition
*contracting sequence*

Let $(x_n)$ be a sequence

$(x_n)$ is contracting if

\[\exists C > 0, \forall n \in \mathbb{N}, | x_{n+1} - x_n | \leq C | x_n - x_{n-1} |\]
#+end_definition
** Convergence
#+begin_theorem
Any contracting sequence is convergent
#+end_theorem
#+begin_proof
Let $(x_n)$ be a contracting sequence

$$ \begin{aligned}
\ | x_{n+1} - x_n| & \leq C |x_n - x_{n-1}| \\
& \leq C^2 | x_{n-1} - x_{n-2} | \\
& \leq C^3 | x_{n-1} - x_{n-2} | \\
& \leq ... \\
& \leq C^{n-1} | x_2 - x_1 |
\end{aligned} $$

$$ \begin{aligned}
\ |x_{n+m} - x_n| & = |x_{n+m} - x_{n+m-1} + ... + x_{n+1} - x_n| \\
& \leq |x_{n+m} - x_{n+m-1}| + ... + |x_{n+1} - x_n| \\
& \leq C^{n+m-1} |x_{n+m} - x_{n+m-1}| + ... + C ^{n-1} |x_{n+1} - x_n| \\
& \leq C^{n-1} (1 + ... + C^m) |x_2 - x_1| \\
& \leq C^{n-1} \frac{1-C^{n+1}}{1-C} |x_2 - x_1| \\
& \leq \frac{C^{n-1}}{1-C} |x_2 - x_1| \\
\end{aligned} $$

$$\lim_{n \to \infty} C^{n-1} = 0$$

So $(x_n)$ is a Cauchy sequence and is convergent
#+end_proof
#+begin_examples
1. x_n = n

   Let $M \geq 0$

   for $n \geq M, x_n \geq M$

   So $(x_n)$ goes to infinity
2. $x_n = 1 - \frac{1}{n} + n \geq M$
3. $x_n = n^2 - n = n(n-1) \geq (n-1)^2$
#+end_examples

** Divergence
#+begin_theorem
Let $(x_n)$ be increasing and not bounded. Then $$\lim_{n \to \infty} x_n = \infty$$

Let $(x_n)$ be decreasing and not bounded. Then $$\lim_{n \to -\infty} x_n = -\infty$$
#+end_theorem
#+begin_proof
Let $(x_n)$ be increasing and not bounded
Let $M \geq 0$, Since $(x_n)$ is not bounded, you can find $n \geq 0$ s.t. $x_n \geq M$
For $k \geq n, x_k \geq x_n$ so $x_k \geq x_n \geq M$

If $(x_n)$ is decreasing and bounded, $(-x_n)$ is increasing and not bounded,

so $$\lim_{n \to \infty} -x_n = \infty$$

$$\lim_{n \to \infty} x_n = -\infty$$
#+end_proof

Let $(x_n),(y_n)$ be sequences s.t. $(x_n) \geq (y_n)$

$$\lim_{n \to \infty} (y_n) = \infty$$ implies 

$$\lim_{n \to \infty} (y_n) = \infty$$

*** Proving divergence
#+begin_proof
Let $M \geq 0$

We can find $N \geq 0$ s.t. for $n \geq N$, $x_n \geq M$

So $y_n \geq M$

$$\lim_{n \to \infty} y_n = \infty$$
#+end_proof

* Series
#+begin_definition
_series_

A sequence generated by the sum of the first $n$ terms of another sequence

The series $(s_n)$ generated by $(x_n)$ lookks like:

$s_1 = x_1$

$s_2 = x_1 + x_2$

...

$s_n = x_1 + ... + x_n$
#+end_definition

#+begin_definition
_limit of series_

$$\lim_{n \to \infty} s_n = \sum_{k=1}^{\infty} x_k$$
#+end_definition

#+begin_examples
1. Let $(x_n) = \frac{1}{n(n+1)}$

   Then 

   $$ \begin{aligned}
   (s_n) & = \sum_{k=1}^{\infty} \frac{1}{k(k+1)} \\
   & = \sum_{k=1}^{\infty} \frac{1}{k} - \sum_{k=1}^{\infty} \frac{1}{k+1} \\
   & = \sum_{k=1}^{\infty} \frac{1}{k} - \sum_{k=2}^{\infty} \frac{1}{k} \\
   & = 1 - \frac{1}{n+1}
   \end{aligned} $$
   
2. Let $(x_n) = r^{n-1}$

   then

   $$ \begin{aligned}
   s_n & = \sum_{k=1}^{\infty} r^{n-1} \\
   & = \frac{1-r^n}{1-r}
   \end{aligned} $$

   case $|r| < 1$

   $$\lim_{n \to \infty} r^n = 0$$

   So
   $$\sum_{k=1}^{\infty} r^{n-1} = \frac{1}{1-n}$$

   and $(s_n)$ is convergent
   
   case $|r| = 1$

   $$\sum_{k=1}^{\infty} x_k = \infty$$

   $s_n = \frac{1}{2} (1 - (-1^n))$

   So $(s_n)$ is divergent

3. Let $x_n = \frac{1}{2^n}$

   then $$\lim_{n \to \infty} s_n = \sum_{k=1}^{\infty} \frac{1}{2^k} = 2$$
#+end_examples

#+begin_theorem
Let $(s_n)$ be a series generated by the sequence $(x_n)$

If $(s_n)$ converges, then $(x_n)$ also converges
#+end_theorem
#+begin_proof
Since $x_n = s_n - s_{n-1}$

$$\lim_{n \to \infty} x_n = \lim_{n \to \infty} s_n - \lim_{n \to \infty} s_{n-1} = 0$$

So $(x_n)$ is convergent
#+end_proof

Convergence of $(x_n)$ does not imply convergence of $(s_n)$

ex. harmonic series = $x_n = \frac{1}{n}$

#+begin_theorem
If $(x_n)$ is a positive sequence

then $$0 < \lim_{n \to \infty} s_n \leq \infty$$
#+end_theorem
#+begin_proof
Since $(x_n)$ is positive, $(s_n)$ is increasing.

Increasing series are either bounded and convergent

or unbounded and divergent
#+end_proof

#+begin_theorem
Let $(x_n)$ and $(y_n)$ be sequences s.t. $0 \leq x_n \leq y_n$

Let $(s_n)$ and $(t_n)$ be sequences of $(x_n)$ and $(y_n)$ respectively

If $(t_n)$ is convergent, then $(s_n)$ is convergent

If $(s_n)$ is divergent, then $(t_n)$ is divergent
#+end_theorem
#+begin_proof
$0 \leq x_1 \leq y_1$

$0 \leq x_2 \leq y_2$

...

$0 \leq x_n \leq y_n$

So, $0 \leq s_n \leq t_n$


Assume $(t_n)$ is convergent.

Then $(t_n)$ is bounded, then $(s_n)$ is bounded.

Since $(s_n)$ is increasing and bounded, it is convergent


Assume $(s_n)$ is divergent.

then $(s_n)$ is unbounded, then $(t_n)$ is unbounded

Since $(s_n)$ is increasing and unbounded, it is divergent
#+end_proof

#+begin_examples
1. Let $x_n = \frac{1}{n^r}, r \geq 0$

   then 

   $$ \begin{aligned}
   s_n = \sum_{k=1}^{\infty} \frac{1}{k^r} \
   & = 1 + \frac{1}{2^r} + ...
   \end{aligned} $$

   *case* $0 \leq r \leq 1$

   $\frac{1}{n^r} \geq \frac{1}{n}$

   So $s_n$ is divergent

   *case* $r > 1$

   For $n \geq 2$ (by bernoulli inequality)

   $\frac{1}{nr} \leq \frac{1}{r-1} (\frac{1}{(n-1)^{r-1}} - \frac{1}{n^{r-1}})$

   Let $y_n = \frac{1}{r-1} (\frac{1}{(n-1)^r} - \frac{1}{n^{r-1}})$

   Then $$\sum_{k=1}^{\infty} y_k = \frac{1}{r-1}(1 - \frac{1}{n^{r-1}}) < \infty$$

   So $$\sum_{k=1}^{\infty} x_k < \infty$$

   We conclude $$\sum_{k=1}^{\infty} \frac{1}{n^r} < \infty$$ if and and only if $r > 1$
#+end_examples
* Functions
#+begin_definition
*cluster point*

[[./cluster_point.png]] 

Let $A \subseteq \mathbb{R}$ be a non empty set. 

Then $c \in \mathbb{R}$ is a cluster point of A if

$\exists a \in A$, $a \neq c$  s.t. $\forall \varepsilon > 0$,

$|a - c| < \varepsilon$
#+end_definition

$c$ is a cluster point of the set 
$A$ if the values of $A$ get arbitrarily close to $c$

#+begin_examples
1. Let $A = \{ \frac{1}{n}, n \in \mathbb{N}\}$

   0 is the only cluster point for the set $A$

2. Let $A = \{n | n \in \mathbb{N}\}$

   There are no cluster points in the set.  We can always find a smaller $\varepsilon$ which excludes $c$

3. Let $A = \mathbb{Q} = \{\frac{x}{y} | x,y \in \mathbb{N}\}$

   The set of cluster points is $\mathbb{R}$

   This is because $\mathbb{Q}$ is dense in $\mathbb{R}$
#+end_examples

#+begin_definition
*function*

Let $A \subset \mathbb{R}$ be a non empty set.

Then the mapping $f: A \rightarrow \mathbb{R}$ is a function
#+end_definition

#+begin_definition
*limit*

$f$ admits a limit $L \in \mathbb{R}$ if:

$\forall \varepsilon > 0$, $\exists \zeta > 0$,

 s.t. $|x - a| \leq \zeta$ implies $|f(x) - L| \leq \varepsilon$
#+end_definition

Or, as $x$ converges to $a$, $f(x)$ converges to $L$

#+begin_examples
[[./function_limit_example1.png]]

Let $f(x) = x$

Let $a \in \mathbb{R}$, $\varepsilon > 0$

if $|x - a| \leq \varepsilon$,

then $|f(x) - a| \leq \varepsilon$
#+end_examples

#+begin_theorem
_Uniqueness of Limit_

Let $A \subseteq \mathbb{R}$ be a nonempty set

Let $f: A \to \mathbb{R}$ and let $c \in \mathbb{R}$ be a cluster point of $A$

Assume $f$ has a limit $L$ at $c$ and also has limit $L'$ at $c$

Then $L = L'$

and $L = \lim_{x \to c} f(x)$ is called the limit of $f$ at $c$
#+end_theorem

#+begin_proof
Let $\varepsilon > 0$

Since $L$ is a limit, $\exists \zeta > 0$ s.t.

$|x - a| \leq \zeta \Rightarrow |f(x) - L| \leq \varepsilon$

Since $L'$ is a limit, $\exists \zeta' > 0$ s.t.

$|x - a| \leq \zeta' \Rightarrow |f(x) - L'| \leq \varepsilon$

Let $x \in \mathbb{R}$ s.t.

$|x - a| \leq \min(\zeta, \zeta')$

Then 

$$ \begin{aligned}
\ |L - L'| & \leq |L - f(x) + f(x) - L'| \\
& \leq |L - f(x)| + |f(x) - L| \\
& \leq \varepsilon + \varepsilon \leq 2 \varepsilon
\end{aligned} $$
#+end_proof

#+begin_examples
1. find the limit of $f(x) = a, a \in \mathbb{R}$

   Let $\varepsilon > 0$

   For $x \in \mathbb{R}$, s.t. $|x - 1| \leq 1$

   we have $|f(x) - a| < \varepsilon$

2. Let $f(x) = x$.  Show $\lim_{x \to 1} f(x) = 1$

   Let $\varepsilon > 0$

   for $x \in \mathbb{R}$ s.t. $|x - 1| < \varepsilon$ we have $|f(x) - 1| = |x - 1| < \varepsilon$

3. Let $f(x) = x^2$  Show $\lim_{x \to a} f(x) = a^2$

   Let $\varepsilon > 0$

   $|x^2 - a^2| = |x-a||x+a|$

   If $|x - a| \leq 1$, $|x| \leq 1 + |a|$,

   so $|x + a| \leq 1 + 2 |a|$

   $|x^2 - a^2| \leq |x-a|(1 + 2 |a|)$

   Let $\zeta = \min(1, \frac{\varepsilon}{1 + 2 |a|})$

   For $x \in \mathbb{R}$ s.t. $|x - a| \leq \zeta$,

   we have $|x^2 - a^2| < \varepsilon$

4. Let $f(x) = \frac{1}{x}, x > 0$.  Prove $\lim_{x \to a} \frac{1}{x} = \frac{1}{a}$

   $|\frac{1}{x} - \frac{1}{a}| = \frac{|a - x|}{|a||x|}$

   For $|x - a| < \frac{a}{2}, x > \frac{a}{2}$

   we have $|\frac{1}{x} - \frac{1}{a}| \leq \frac{2}{a^2} |a - x|$

   Let $\zeta = \min(\frac{a}{2}, \frac{\varepsilon a^2}{2})$

   if $|x - a| \leq \zeta$

   then $|\frac{1}{x} - \frac{1}{a}| \leq \varepsilon$
#+end_examples

#+begin_theorem
Let $A \subset \mathbb{R}$ be a nonempty set and $f: A \rightarrow \mathbb{R}$

Let c be a cluster point of A.  Then the conditions are equivalent:

1. $\lim_{x \to c} f(x) = L$
2. For every sequence $(x_n)$ in A where $x_n \neq c$ and $\lim_{n \to \infty} x_n = c$,

   then $\lim_{n \to \infty} f(x_n) = c$
#+end_theorem

#+begin_proof
We must show that 1 implies 2 and 2 implies 1.

_1 -> 2_

Assume that 1 is true.  Let $x_n$ be a sequence s.t. $x_n \neq c$ and $\lim_{n \to \infty} x_n = c$

Let $\varepsilon > 0$.  We can find $\zeta > 0$ s.t.

for $x \in (c - \zeta, c + \zeta), x \neq c$ we have $|f(x) - L| \leq \varepsilon$

Since $x_n$ converges to $c$, we can find $K$ s.t.

for $n \geq K$, $x_n \in (c - \zeta, c + \zeta)$

For $n \geq K, |f(x_n) - L| \leq \varepsilon$

_2 -> 1_

Assume for contradiction that 2 is true, and 1 is not true.

There exists $\varepsilon_0 > 0, \forall \zeta > 0$

$\exists x \in (c - \zeta, c + \zeta), x \neq c$

$|f(x) - L| > \varepsilon_0$

So, $\exists x _n \in (c - \frac{1}{n}, c + \frac{1}{n}), x_n \neq c$

$|f(x_n) - L| > \varepsilon_0$

We have that $\lim_{n \to \infty} x_n = c$, but $\lim_{n \to \infty} f(x_n) \neq L$

This contradicts 2
#+end_proof

#+begin_theorem
Let $A \subset \mathbb{R}$ be nonempty, $f:A \rightarrow \mathbb{R}$, and $c \in \mathbb{R}$ be a cluster point of A

1. Assume that you can find a sequence $(x_n)$ in A, $x_n \neq c$ and $x_n \rightarrow c$, but $f(x_n)$ is not convergent

   Then $\lim_{x \ to c} f(x)$ does not exist
#+end_theorem

#+begin_examples
1. Let $f(x) = \frac{1}{x}, x > 0$

   Let $x_n = \frac{1}{n}.  We have $x_n \to 0, $f(x_n)$ is convergent so 

   $\lim_{x \to 0} f(x)$ does not exist

2. Show the function does not converge

   $$ f(x) =
   \begin{cases}
   1 & x \in \mathbb{Q} \\
   0 & \text{else}
   \end{cases} $$

   Let $(x_n) = \frac{1}{n}$.  $\lim_{n \to \infty} f(x_n) = 1$

   Let $(y_n) = \frac{\sqrt{2}}{n}$.  $\lim_{n \to \infty} f(x_n) = 0$

   Since the subsequences don't converge to the same value, $f(x)$ does not converge
#+end_examples

** Limit Theorems
#+begin_definition
Let $A \subset \mathbb{R}$ be a nonempty set.  Let $c \in \mathbb{R}$ be a cluster point of $A$.  Let $f: A \longrightarrow \mathbb{R}$

Then $f$ is bounded in a neighborhood of c if there exists $M > 0$ and $\zeta > 0$

s.t. if $x\in[c - \zeta, c + \zeta] \cap A$

$|f(x) \leq M$
#+end_definition

#+begin_examples
1. Let $f(x) = x^2$.  For $x \in [-1,1]$, $f(x) \leq 1$ so $f$ is bounded in the neighborhood of 0
   
2. Let $f(x) = \frac{1}{x}$
#+end_examples


#+begin_theorem
Let $f: A \longrightarrow \mathbb{R}$ Let $c$ be a cluster point of $A$.  

If $\lim_{x \to c} f(x)$ exists, then $f$ is a bounded in a neighborhood of $c$
#+end_theorem

#+begin_proof
Let $L = \lim_{x \to 1} f(x)$.  We can find $\zeta > 0$

s.t. for $x \in [c - \zeta, c + \zeta] \cap A, x \neq c$,

$|f(x) - L| \leq 1$

We have $|f(x)| \leq 1 + |L|$
#+end_proof

#+begin_definition

Let $f,g: A \longrightarrow \mathbb{R}$

- $(f + g)(x) = f(x) + g(x)$
- $(fg)(x) = f(x)g(x)$
- if $\forall x \in A, g(x) \neq 0$

  $\frac{f}{g}(x) = \frac{f(x)}{g(x)}$
#+end_definition

#+begin_theorem
Let $f,g: A \longrightarrow \mathbb{R}$

Let c \in \mathbb{R} be a cluster point of $A$

If $\lim_{x \to c} f(x)$ and $\lim_{x \to c} g(x)$ exist, then

$\lim_{x \to c} f(x) + \lim_{x \to c} g(x) = \lim_{x \to c} f(x) + g(x)$
#+end_theorem

#+begin_proof
Let $(x_n)$ be a sequence in $A$, s.t. $\lim_{n \to \infty} x_n = c$ and $x_n \neq c$

Since $\lim_{n \to \infty} x_n$ exists, the sequence $f(x_n)$ is convergent and $\lim_{n \to \infty} f(x_n) = \lim_{n \to c} f(x)$

similarly,  $\lim_{n \to \infty} g(x_n) = \lim_{n \to c} g(x)$

so, $f(x_n) + g(x_n)$ is convergent and $\lim_{n \to \infty} f(x_n) + g(x_n) = \lim_{n \to \infty}f(x_n) + \lim_{n \to \infty}g(x_n) = \lim_{n \to c}f(x) + \lim_{n \to c}g(x)$ 
#+end_proof

#+begin_theorem
Let $f,g: A \to \mathbb{R}$.  Let $c \in \mathbb{R}$ be a cluster point of $A$.

If $\lim_{x \to c} f(x)$ and \lim_{x \to c} g(x)$ exist, then

$\lim_{x \to c} f(x)g(x) = \lim_{x \to c} f(x) \lim_{x \to c} g(x)$
#+end_theorem

#+begin_examples
1. Find $\lim_{x \to 1} \frac{x^2 + 1}{x}$

  $\lim_{x \to 1} \frac{x^2 + 1}{x} = \frac{\lim_{x \to 1} x^2 + 1}{\lim_{x \to 1} x} = 2$
   
2. Let $f(x) = x + \mathbb{1}_{\mathbb{Q}}$

   The limit of $x$ exists, but not $\mathbb{1}_{\mathbb{Q}}$, so the limit of $f(x)$ does not exist

3. Let $f(x) = x \mathbb{1}_{\mathbb{Q}}$

   Since $\mathbb{1}_{\mathbb{Q}}$ is bounded and $x$ is convergent, $f(x)$ is convergent
#+end_examples

** Squeeze Theorem
#+begin_theorem
Let $f,g,h: A \to \mathbb{R}$.  Let $c \in \mathbb{R}$ be a cluster point of $A$.

Assume $f \leq g \leq h$ for all $x$.

If $\lim_{x \to c} f(x) = \lim_{x \to c} h(x) = L$, then $\lim_{x \to c} g(x) = L$
#+end_theorem

#+begin_proof
Let $(x_n) \in A$ be a sequence which converges to $c$, but $x_n \neq c$

$\lim_{n \to \infty} f(x_n) = \lim_{n \to \infty} h(x_n) = L$

From the squeeze theorem for sequences, $g(x_n)$ converges and $\lim_{n \to \infty} g(x_n) = L$
#+end_proof
M > 0.  prop div if x_n > M for all n > k

** Proper Divergence
#+begin_definition
Let $f: A \to \mathbb{R}$  Let $c \in \mathbb{R}$ be a cluster point of $A$

We say that $\lim_{x \to c} f(x) = \infty$

if for $\forall M \geq 0$, $\exists \zeta > 0$, s.t. for $x \in [c - \zeta, c + \zeta] \cap A, x \neq c$

$f(x) \geq M$
#+end_definition
#+begin_examples
1. $f(x) = \frac{1}{x}, x > 0$

   $\lim_{x \to 0} f(x) = \infty$

2. Let $f(x) = \frac{1}{x}, x < 0$

   $\lim_{x \to 0} f(x) = -\infty$
#+end_examples
*changing A can change the limit*

#+begin_theorem
Let $f: A \to \mathbb{R}$.  Let $c \in \mathbb{R}$ be a cluster point of $A$

then $\lim_{x \to c} f(x) = \infty$ iff 

for every sequence $(x_n) \in A$ converging to $c$, $x_n \neq c$

$\lim_{n \to \infty} f(x_n) = \infty$
#+end_theorem
#+begin_proof
_1 -> 2_

Assume that $\lim_{x \to c} f(x) = \infty$

Let $M > 0$.  We can find $\zeta > 0$

s.t. for $x \in [c - \zeta, c + \zeta] \cap A, f(x) > M, x \neq c$

Since $x_n$ converges to $c$, we can find $N \geq 0$, s.t. for $n \geq N, x_n \in [c - \zeta, c + \zeta]$ and $f(x_n) \geq M$

so $\lim_{n \to \infty} f(x_n) = \infty$

_2 -> 1_

Assume for contradiction that $\lim_{x \to c} f(x) \neq \infty$.  Then we can find $M > 0$ s.t. $\forall \zeta$,

there exists $x \in [c - \zeta, c + \zeta] \cap A, x \neq c$ where $f(x) \leq M$

Let $\zeta = \frac{1}{n}$.  $x_n \in [c - \zeta, c + \zeta], f(x_n) \leq M$

we don't have $\lim_{n \to \infty} f(x_n) = \infty$ which is a contradiction
#+end_proof
** Continuous Functions
#+begin_theorem
*Continuous at point*

Let $\varepsilon > 0$. 

$f$ is continuous at $c$ if there exists $\zeta > 0$ such that

$\forall x \in A, |x - c| \leq \zeta$ implies $|f(x) - f(c)| \leq \varepsilon$

#+end_theorem

[[./continuous_def.png]] 

If $c \in A$ is a cluster point of A, 

then $f$ is a continuous function at $c$ iff $\lim_{x \to c} f(x) = f(c)$

If $c \in A$ is not a cluster point, then $f$ is automatically continuous at $c$

#+begin_examples
1. Let $f(x) = x, x \in \mathbb{Z}$.

   Then $f$ is continuous at $x$

2. Let 

   $$ f(x) =
   \begin{cases}
   1 & x \geq 0 \\
   0 & x < 0
   \end{cases} $$

   Then $f$ is not continuous at 0

3. Let 

   $$ f(x) =
   \begin{cases}
   1 & x \in \mathbb{Q} \\
   0 & x \notin \mathbb{Q}
   \end{cases} $$

   f(x) is nowhere continuous

4. Let 

   $$ f(x) =
   \begin{cases}
   1 & x \in \mathbb{R} \\
   0 & x \notin \mathbb{R} 
   \end{cases} $$

   from the squeeze theorem, $f$ is continuous at 0

   but if $x \neq 0$, then the limit does not exist and $f$ is not continuous
#+end_examples

#+begin_theorem
*Continuity of points*

Let $A \rightarrow \mathbb{R}$

Let $c \in A$, then $f$ is continuous at $c$ iff

for every $(x_n)$ s.t. $\lim_{n\to \infty} x_n = c$, we have $\lim_{n\to \infty} f(x_n) = f(c)$

$f$ is not continuous at $c$, iff there exists $(x_n)$ that converges to c

where $f(x_n)$ does not converge to $f(c)$
#+end_theorem

#+begin_definition
*Continuity of functions*

Let $f:A \to \mathbb{R}$

Let $B \subset A$

We say $f$ is continuous on $B$ if $f(x)$ is continuous for every $x \in B$
#+end_definition
#+begin_examples
1. Let $f(x) = 1, x > 0$

   $f$ is continuous on $(0, \infty)$

   Let $f:A \to \mathbb{R}$ and $c \in \mathbb{R}$ be a cluster point of $A$. 

   Assume $c \notin A$, but $\lim_{x \to c} f(x)$ exists.  Then we can define

   $f'(x) = f(x), x in A, \lim_{x \to c}f(x), x = c$

   f' fills in holes
#+end_examples

** Combinations of continuous functions
#+begin_theorem
Let $f,g:A \to \mathbb{R}$ be continuous functions at $c$.  Let $c \in A$

Then $f+g$, $fg$, and $\frac{f}{g}$ ($g \neq 0$) are continuous at $c$
#+end_theorem
#+begin_proof
Let $(x_n) \in A$ converge to $c$. 

Since $f,g$ are continuous at $c$,

$\lim_{n \to \infty} f(x_n) = f(c)$ and $\lim_{n \to \infty} g(x_n) = g(c)$

so $\lim_{n \to \infty} f(x_n) + \lim_{n \to \infty} g(x_n) = f(c) + g(c)$ 

The proof is identical for $fg$ and $\frac{f}{g}$
#+end_proof
#+begin_examples
1. Let $f$ be any polynomial in $\mathbb{R}$

   Since $f$ is a sum of products of $x$ and $x$ is continuous on $\mathbb{R}$, $f$ is also continuous on $\mathbb{R}$
#+end_examples
#+begin_theorem
Let $f:A \to \mathbb{R},g:B \to \mathbb{R}$

Assume for $x \in B$, $g(x) \in A$

We define $(f \circ g)(x) = f(g(x))$

If $g$ is continuous at $c$ and $f$ is continuous at $g(c)$, then $f \circ g$ is continuous at $c$
#+end_theorem
#+begin_proof

#+end_proof
#+begin_theorem
Let $A,B \subseteq \mathbb{R}$.  Let $f$ be continuous on $A$, and $g$ be continuous on $B$

If $f(A) \subseteq B$, then $g \circ f$ is continuous on $A$
#+end_theorem

closed set/function

** Intervals
#+begin_definition
interval is a continuous subset of R
#+end_definition

#+begin_theorem
*f has a supremum on a bounded set*
*uses squeeze theorem*


Assume that $f$ is not bounded on $I$.  We can assume $f$ has no upper bound.

$n$ is not an upper bound for $f$, so we can find $(x_n) \in I$ s.t. $f(x_n) \geq n$

$(x_n)$ is bounded, therefore it admits a convergent subsequence $(x_m)$

Let $x^* = \lim x_m$

Since I is closed, $x^* \in I$

Since $f$ is continuous at $x^* \lim f(x_m) = \lim f(x^*)$

This contradicts $f(x_n) \geq n$

So $f$ admits a supremum on $I$

The proof is similar for infimum
#+end_theorem

#+begin_theorem
*The supremum/infimum of a function of closed set is also a min/max*

Let $I = [a,b]$.  Let $f:I \to \mathbb{R}$ be a continuous function.

Let $M = \text{sup}{f(x), x \in I}$, $S = \inf {f(x), x \in I}$

$\exists x_S, x_M \in I$ s.t. $f(x_S) = S, f(x_M) = M$
#+end_theorem

#+begin_proof
Let $f: I \to \mathbb{R}$.  $S = \sup f$

We can find a sequence $x_n \in I$ s.t. $f(x_n)$ converges to $S$.

We can find a convergfent subsequence $x_m$.

Let $x^* = \lim x_m$

Since $f$ is continuous at $x^*$,

$\lim f(x_m) = f(x^*)$

Therefore $S = f(x^*)$
#+end_proof

#+begin_examples
1. Let $f(x) = x^2, I = [-1, 1]$

   $\sup{F} = 1 = f(1)$

   $\inf{F} = 0 = f(0)$

2. Let $f(x) = x, I = (0,1)$

   $\inf f = 0$, but there is no $x \in I$ such that $f(x) = 0$
#+end_examples

#+begin_theorem
*Intermediate Value Theorem*

Let $I$ be an interval and $f:I \to \mathbb{R}$ be continuous

Let $a,b,c \in I$ s.t. $a \leq b$ $f(a) \leq f(b)$

Let $\lambda \in [f(a), f(b)]$.  We can always find $c \in [a,b]$

s.t. $f(c) = \lambda$
#+end_theorem

#+begin_proof
Let $A = {x \in [a,b], f(x) \leq \lambda}$

$A \neq crosszero$ and is bounded so $A$ has an upper bound

Let $c = \sup A$

Let $(x_n)$ be a sequence in $A$, s.t. $\lim x_n = c$

Since $x_n \in A$, f(x_n) \leq \lambda$

Since $f$ is continuous at $c$, $\lim f(x_n) = f(c)$

Therefore $f(c) \leq \lambda$

For $n \geq 1$, $c + \frac{1}{n} \notin A$, so $f(x + \frac{1}{n} > \lambda$

So $f(c) \geq \lambda$

We conclude $f(c) = \lambda$
#+end_proof

#+begin_theorem
*Zero crossing corollary*

Let $f:[a,b] \to \mathbb{R}$ be continuous

If $f(a) < 0, f(b) > 0$ then $\exists c$ s.t. $f(c) = 0$
#+end_theorem

#+begin_theorem
Let $f:\mathbb{R} \to \mathbb{R}$ be continuous.  Let $I \in \mathbb{R}$ be an interval.

Then $f(I) = {f(x) | x \in I}$ is an interval
#+end_theorem

#+begin_proof
Let $I$ be an interval.  Let $a,b$ s.t. $a \leq b$ and $a,b \in f(I)$

Since $a \in f(I), \exists \alpha \in I$ s.t.

$f(\alpha) = a$

Since $b \in f(I), \exists \beta \in I$ s.t.

$f(\beta) = b$

For $c \in [a,b]$ we can find $\gamma \in [\alpha, \beta]$ s.t. $f(\gamma) = c$

So $f(\gamma) = c$.  Therefore $f(I)$ is an interval
#+end_proof

** Uniform continuity
#+begin_definition
$f$ is uniformly continuous if

for all $\varepsilon$ there exists $\delta$ such that

$|x_1 - x_2| \leq \delta$ implies $|f(x_1) - f(x_2)| \leq \varepsilon$
#+end_definition

#+begin_definition
*Lipschitz*

Let $f:A \to \mathbb{R}$

$f$ is lipschitz if, there exists $K \geq 0$ such that

for all $x, y \in A$

$|f(x) - f(y)| \leq K|x - y|$
#+end_definition

#+begin_examples
1. Let $f(x) = x$.

   $|f(x) - f(y)| \leq 1 * |x - y|$, so $f$ is lipschitz

2. Let $f(x) = \sqrt{x}$

   $|f(x) - f(y)| = |\sqrt{x} - \sqrt{y}| = \frac{1}{\sqrt{x} + \sqrt{y}} |x - y|$
   
   so $f$ is not lipschitz on $[0, \infty)$.

   If we let $x,y \in [a, \infty)$, then

   $|f(x) - f(y)| \leq \frac{1}{2\sqrt{a}} |x - y|$

   so $f$ is lipschitz on $[a, \infty)$

3. Let $f(x) = x^2$

   $|f(x) - f(y)| = |x^2 - y^2| = |x - y||x + y|$.

   $f$ is not lipschitz on $\mathbb{R}$

   but it is for any bounded interval, since some $K$ will be greater than $|x - y|$
#+end_examples

#+begin_theorem
Any lipschitz function is uniformly continuous
#+end_theorem

#+begin_proof
Let $\varepsilon > 0$.  For $x,y \in A$ such that $|x - y| \leq \frac{\varepsilon}{K}$

we have $|f(x) - f(y)| \leq \varepsilon$
#+end_proof

The converse is not true, as $f(x) = \sqrt{x}$ is uniformly continuous, but not lipschitz

#+begin_definition
The derivative of Lipschitz functions are bounded by K
#+end_definition

** Monotonic functions
#+begin_definition
*Increasing and decreasing functions

Let $f:A \to \mathbb{R}$, and $x,y \in A$, such that $x \leq y$

then $f$ is increasing if $f(x) \leq f(y)$

the definition is similar for strictly increasing/decreasing
#+end_definition

#+begin_examples
1. Let $f(x) = x$

   $f$ is strictly increasing

2. Let $f(x) = x^2$

   $f$ is strictly increasing on the domain $x \geq 0$
#+end_examples

#+begin_theorem
_The left and right limits exist for all points in monotonic functions._

Let $f:I \to \mathbb{R}$ be monotonic.

Let $c \in I$ which is not an endpoint of $I$.

Then $\lim_{x \to +c} f(x)$ and $\lim_{x \to -c} f(x)$ exist
#+end_theorem

#+begin_proof
Let $f$ be increasing. $\varepsilon > 0$, and $c \in \mathbb{R}$

Let $L = \sup\{f(x)| x < c\}$

$L - \varepsilon$ is not an upper bound, so

there exists $x_{\varepsilon} < c$ such that $f(x_{\varepsilon}) > L - \varepsilon$.

For $x \in [x_{\varepsilon}, c)$

$L - \varepsilon \leq f(x) \leq L$

so $\lim_{x \to +c} f(x) = L$, $\lim_{x \to -c} f(x) = L$.

The proof is similar for right limits and infimums
#+end_proof

** Inverse functions

#+begin_definition
*Inverse*
The function $g:f(A) \to A$ such that $g(f(a)) = a$ for $a \in A$

A function $f$ has an inverse if $f$ is injective. ($f$ uniquely maps values in its domain)

ie. $x \neq y$ implies $f(x) \neq f(y)$ 
#+end_definition

#+begin_theorem
Let $f:A \to \mathbb{R}$ be a strictly increasing function.

Then $f$ is injective and $g:f(A) \to A$ is strictly increasing.
#+end_theorem

#+begin_proof
Let $x,y \in A$ such that $x \neq y$

Since $f$ is increasing, we have $x < y$ or $x > y$, so

$f(x) < f(y)$ or $f(x) > f(y)$, so $f(x) \neq f(y)$

so $f$ is injective.

Let $y_1,y_2 \in f(A)$ such that $y_1 < y_2$

We have $y_1 = f(x_1), y_2 = f(x_2)$ for some $x_1,x_2 \in A$

We must have $x_1 < x_2$, so $f^{-1}{y_1} < f^{-1}{y_2}$
#+end_proof

#+begin_theorem
Let $f$ be a strictly increasing and continuous function.  Then $f^{-1}$ is strictly increasing and continuous.
#+end_theorem

#+begin_proof
Let $f(I) = J$

Assume for contradiction that $g$ is not continuous.

Then $g(J) = g(f(I)) = I$ is not an interval, which is a contradiction
#+end_proof

* Test II Review

- a function which is continuous on a bounded and closed interval is uniformly continuous

- if a function is uniformly continuous on an open interval, the limits at the endpoints exist

- a function is uniformly continuous on a bounded interval iff the limits exist at the endpoints
* Derivatives
#+begin_definition
*Differentiability*

We say that a function $f:I_1 \to \mathbb{R}$ is differentiable at $c \in I$ if

\[\lim_{x \to c} \dfrac{f(x) - f(c)}{x - c}\]

exists.  We call this $f'(c)$
#+end_definition

#+begin_examples
1. Let $f(x) = c$ for $c \in \mathbb{R}$

   $\frac{f(x) - f(c)}{x - c} = 0$

   so $f'(x) = 0$

2. Let $f(x) = x$
   
   $\frac{f(x) - f(c)}{x - c} = \frac{x - c}{x - c} = 1$

   so $\lim_{x \to c} f'(x) = 1$

3. Let $f(x) = x^2$

   $\frac{f(x) - f(c)}{x - c} = \frac{x^2 - c^2}{x - c} = \frac{(x - c)(x + c)}{x - c} = x + c$

   so $\lim_{x \to c} x + c = 2c$

4. Let $f(x) = x^3$

   $\frac{f(x) - f(c)}{x - c} = \frac{x^3 - c^3}{x - c} = \frac{(x - c)(x^2 + xc + c^2)}{x - c} = x^2 + xc + c^2$

   so $\lim_{x \to c} x^2 + xc + c^2 = 3c^2$
#+end_examples

#+begin_theorem
If a function is differentiable at c, it is continuous at c
#+end_theorem

#+begin_proof
Let $f:I \to \mathbb{R}$ be differentiable.  Then $\lim_{x \to c} \frac{f(x) - f(c)}{x - c} = L$

$\frac{f(x) - f(c)}{x - c}(x - c) = L(x-c)$

so $\lim_{x \to c} f(x) - f(c) = \lim_{x \to c} \frac{f(x) - f(c)}{x - c} \times \lim_{x \to c} (x-c) = f'(c) \times 0 = 0$

so $\lim_{x \to c} f(x) = f(c)$
#+end_proof

#+begin_theorem
The derivative of a sum of functions is the sum of the derivative of the functions

$(f + g)'(x) = f'(x) = g'(x)$
#+end_theorem

#+begin_proof
\[(f + g)'(c) = \frac{f(x) + g(x) - (f(c) + g(c)) }{x - c} = \frac{f(x) - f(c)}{x - c} +  \frac{g(x) - g(c)}{x - c}\]
so

\[\lim_{x \to c} (f + g)'(c) = f'(c) + g'(c)\]
#+end_proof

#+begin_theorem
$(fg)'(c) = f'(c)g(c) = f(c)g'(c)$
#+end_theorem
#+begin_proof
\[\frac{f(x)g(x) - f(c)g(c)}{x - c} = \frac{f(x)g(x) - f(x)g(c) + f(x)g(c) - f(c)g(c)}{x - c} = f(x) \frac{g(x) - g(c)}{x - c} + g(c) \frac{f(x) - f(c)}{x - c}\]

so $\lim_{x \to c} \frac{f(x)g(x) - f(c)g(c)}{x - c} = f'(c)g(c) + f(c)g'(c)$
#+end_proof

#+begin_theorem
Let $f$ be a differentiable function which is not zero on a neighborhood around $c$

Then $(\frac{1}{f})'(c) = \frac{f'(c)}{f(c)^2}$
#+end_theorem

#+begin_proof
\[\frac{\frac{1}{f(x)} - \frac{1}{f(c)}}{x - c} = \frac{f(c) = f(x)}{f(x)f(c)(x-c)}\]

so 

$\lim_{x \to c} \frac{\frac{1}{f(x)} - \frac{1}{f(c)}}{x - c} = \frac{-f'(c)}{f(c)^2}$
#+end_proof

#+begin_theorem
Let $f,g$ be differentiable functions where $g$ is not zero on a neighborhood around $c$

then $\left(\frac{f}{g}\right)'(c) = \frac{f'g(c) - fg'(c)}{g(c)^2}$
#+end_theorem
#+begin_proof
$\left( \frac{f}{g} \right)(x) = f(x) \frac{1}{g(x)}$

so \[\left(\frac{f}{g}\right)' (c) = f'(c) \times \frac{1}{g(x)} + f(c) \times \left(\frac{1}{g}\right)'(c) = \frac{f'(c)}{g(c)} - f(c) \frac{g'(c)}{g(c)^2} = \frac{f'g(c) - fg'(c)}{g(c)^2}\]
#+end_proof

The Carathéoday Lemma is needed to prove the next theorem.

#+begin_theorem
*Carathéoday Lemma*

Let $f:I \ to \mathbb{R} be continuous.

$f$ is differentiable at $c \in I$ iff,

there exists a continuous $\phi:I \to \mathbb{R}$ such that

$f(x) - f(c) = \phi(x)(x - c)$ for all $x \in I$
#+end_theorem
#+begin_proof
Assume $f$ is differentiable at $c$.  Let 

$$ \phi(x) =
\begin{cases}
\frac{f(x) - f(c)}{x - c} & x \neq c \\
f'(c) & x = c
\end{cases} $$

Then $\phi$ is continuous and $f(x) - f(c) = \phi(x)(x - c)$ for all $x \in I$

Assume $\phi:I \to \mathbb{R}$ is continuous such that $f(x) - f(c) = \phi(x)(x - c)$ for all $x \in I$.

$f(x) - f(c) = \phi(x)(x - c) \rightarrow \frac{f(x) - f(c)}{x - c} = \phi(x)$

$\lim_{x \to c} \frac{f(x) - f(c)}{x - c} = \lim_{x \to c}\phi(x) = \phi(c)$

so $f$ is differentiable at $c$ and $f'(c) = \phi(c)$
#+end_proof

#+begin_theorem
*Chain rule*

Let $f:I \to \mathbb{R}$ and $g:f(I) \to \mathbb{R}$ be continuous.

then $g(f(c))' = g'(f(c))f'(c)$
#+end_theorem
#+begin_proof
By the Carathéoday Lemma,

$f(x) - f(c) = \phi(x)(x - c), x \in I$

$g(y) - g(f(c)) = \Psi(y)(y - f(c)), y \in f(I)$

So $g(f(x)) - g(f(c)) = \Psi(f(x))(f(x) - f(c)) = \Psi(f(x))(\phi(x)(x - c))$

and $\lim_{x \to c} \frac{g(f(x)) - g(f(c))}{x - c} = \Psi(f(c))\phi(f(c)) = g'(f(c))f'(c)$
 
#+end_proof

#+begin_theorem
*Derivative of inverse*

Let $f:I \to \mathbb{R}$ and $f^{-1}:f(I) \to I$ be continuous.

then $f^{-1}'(c) = \frac{1}{f'(g(f(c)))}$
#+end_theorem
#+begin_proof
Since $f$ is continuous and differentiable at $c$, we can find a continuous $\phi$ such that $f(x) - f(c) = \phi(x)(x - c)$.

Let $d = f(c) \in f(I)$ where $f'(c) \neq = 0$

$x = g(y), y \in f(I)$

$f(g(y)) - f(g(d)) = \phi(g(y))(g(y) - g(d))$

$y - d = \phi(g(y))(g(y) - g(d))$

$\phi(g(d)) = f'(c) \neq 0$

Since $\phi(g(y))$ is continuous so $\phi(g(y)) \neq 0$ in a neighborhood around $d$.

so $\lim_{y \to d} \frac{g() - g(d)}{y - d} = \frac{1}{\phi(g(d))} = \frac{1}{f'(g(d))}$
#+end_proof

#+begin_definition
*Relative Extrema*

Let $f: I \to \mathbb{R}$ be continuous.

We say $f$ has a relative minimum at $x_0 \in I$ if there exists $\zeta$ s.t. 

for $x \in [x_0 - \zeta, x_0 + \zeta ] \cap I$

$f(x) \geq f(x_0)$

how does this eliminate constant regions
#+end_definition

#+begin_theorem
"The derivative at local extrema is 0"

Let $f: I \to \mathbb{R}$, $x_0 \in I$, where $x_0$ is not a boundary point

Assume $x_0$ is a relative extrema and $f$ is differentiable at $x_0$

Then $f'(x_0) = 0$
#+end_theorem
#+begin_proof
Assume for contradiction $f'(x_0) > 0$

We know $\lim_{x \to x_0} \frac{f(x) - f(x_0)}{x - x_0} = f'(x_0)$

So there exists $\zeta > 0$ such that

for $x \in [x_0 - \zeta, x_0 + \zeta] \cap I$, we have $\frac{f(x) - f(x_0)}{x - x_0}$

and for $x \in [x_0 - \zeta, x_0]$, we have $f(x) < f(x_0)$

This contradicts that $x_0$ is a relative minimum.

The proof can be repeated for relative maximum.


we cant have f'(x_0) < 0

otherwise ina neighborhood of x_0  f(x)-f(x_0)/(x - x_0) < 0

so x > x_0 implies f(x) < f(x_0)
#+end_proof

#+begin_examples
1. Let $f(x) = |x|$

   There is a relative minimum at 0, but the function is not diff
#+end_examples
